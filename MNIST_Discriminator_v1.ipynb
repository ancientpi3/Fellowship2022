{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rngcpe4pQBvV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#useful parameters\n",
        "num_epochs = 10\n",
        "batch_size = 20\n",
        "lr=0.0002"
      ],
      "metadata": {
        "id": "HFHL3zjqzI1I"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape, activation='relu'))\n",
        "  #model.add(LeakyReLU(alpha=0.2))\n",
        "  #model.add(Dropout(0.4))\n",
        "  #model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "  #model.add(LeakyReLU(alpha=0.2))\n",
        "  #model.add(Dropout(0.4))\n",
        "  model.add(Flatten(input_shape=(28,28,1)))\n",
        "  model.add(Dense(1,input_shape=(None,784), activation='sigmoid'))\n",
        "\n",
        "\n",
        "  opt = Adam(lr=lr, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "PgBZk39RzEWo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "black = np.zeros(shape=(28,28,1))\n",
        "white = np.ones(shape=(28,28,1))\n",
        "#pyplot.imshow(np.resize(black,(28,28)))\n",
        "model = define_discriminator()\n",
        "model.build(input_shape = (28,28,1))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "nvruhqzM1JfN",
        "outputId": "9e7cfa31-cf63-4b1a-81cb-655e7b523d82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 64)        640       \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,185\n",
            "Trainable params: 13,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(np.array([black,white]))\n",
        "model.fit(x = np.array([black,white]), y=np.array([0,1]),epochs = 200)\n",
        "prediction = model.predict(np.array([black,white]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvXjCp7M9Yop",
        "outputId": "86a6ab55-4e7c-490a-ece1-066fa863ece0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1609 - accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1586 - accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1564 - accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1521 - accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1500 - accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1417 - accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1357 - accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1338 - accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1319 - accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1300 - accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1281 - accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1263 - accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1245 - accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1227 - accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1209 - accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1175 - accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1158 - accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1125 - accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1093 - accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1077 - accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1062 - accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1047 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1032 - accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0974 - accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0960 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0947 - accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0933 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0907 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0894 - accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0869 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0857 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0799 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0756 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0746 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0735 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0725 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0706 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0660 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0651 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0634 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0626 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0609 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0594 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0586 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0578 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0571 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0564 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0556 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0509 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0503 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0497 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0473 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0396 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0328 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "l9l5aLlyZ4mI",
        "outputId": "12d64c25-cc53-4e64-c7d9-e65b8c9dfe7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03160866],\n",
              "       [0.99975145]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}