{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rngcpe4pQBvV"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape,activation='relu'))\n",
        "\t#model.add(LeakyReLU(alpha=0.2))\n",
        "\t#model.add(Dropout(0.4))\n",
        "\t#model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\t#model.add(LeakyReLU(alpha=0.2))\n",
        "\t#model.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ]
    }
  ]
}